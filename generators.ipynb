{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a follow up post to the iteration post, which covered what I consider are the basics of iteration. This post covers generators, which are a special type of iter. I'm going to try to avoid, for the most part, using generators to calculate infinite streams of integers (Fibonacci, et al). \n",
      "\n",
      "I also need to admit being a bit of a David Beazley fan boy. His tutorials, writings and talks on generators were extremely influential on my understanding of generators, their uses and composition. As a consequence, I tend to quote him a lot.\n",
      "\n",
      "##What makes a generator a generator\n",
      "The biggest, most obvious difference between generators and other things that make iterators, is that generators *yield* values, not *return* values. Consider the \"cannonical\" implementation of the Fibonacci sequence:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gen_fib():\n",
      "    a, b = 0, 1\n",
      "    yield a\n",
      "    yield b\n",
      "    while True:\n",
      "        yield a+b\n",
      "        a, b = b, a+b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The way a lot of Fibonacci sequences are implemented are with a list, essentially saying, \"I want the first ten digits of Fibonacci\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_fib(n):\n",
      "    fibs = []\n",
      "    if n < 1:\n",
      "        pass\n",
      "    elif n == 1:\n",
      "        fibs.append(0)\n",
      "    elif n == 2:\n",
      "        fibs.extend([0,1])\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        fibs.extend([a,b])\n",
      "        while len(fibs) < n:\n",
      "            fibs.append(a+b)\n",
      "            a, b = b, a+b\n",
      "    return fibs\n",
      "\n",
      "print(list_fib(0))\n",
      "print(list_fib(1))\n",
      "print(list_fib(2))\n",
      "print(list_fib(10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n",
        "[0]\n",
        "[0, 1]\n",
        "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`list_fib` is a mess, we have to check for what was passed in, we need to monitor the size of the list (even using `collections.deque` doesn't *quite* solve this problem). There's a while loop we might hit. But all of this is needed to make sure we correctly construct the list of Fibonacci numbers.\n",
      "\n",
      "By contrast, the `gen_fib` function is simple, clean, there's only one form of flow control. Well, it looks like there's only one form of flow control, but the logic inside of it is *much* more complicated.\n",
      "\n",
      "##Under the hood\n",
      "So what happens when we call `gen_fib`?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(gen_fib())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<generator object gen_fib at 0x7f61c427cb88>\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A generator object pops out. Odd. *I* don't see any object instantiation going on inside of the function. Let's talk a closer look using the `inspect` modules, in particular there are two functions in there of intrest: `isgenerator` and `isgeneratorfunction`. Of course, there's also the usual tools of `type` and `hasattr`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from inspect import isgenerator, isgeneratorfunction\n",
      "\n",
      "f = gen_fib()\n",
      "\n",
      "print(\"isgeneratorfunction(gen_fib):\", isgeneratorfunction(gen_fib))\n",
      "print(\"isgenerator(f):\", isgenerator(gen_fib()))\n",
      "print(\"type(f):\", type(f))\n",
      "print(\"type(iter(gen_fib())):\", type(iter(f)))\n",
      "print(\"Are generators their own iterators?\", f is iter(f))\n",
      "print('f hasattr __iter__:', hasattr(f, '__iter__'))\n",
      "print('f hasattr __next__:', hasattr(f, '__next__'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "isgeneratorfunction(gen_fib): True\n",
        "isgenerator(f): True\n",
        "type(f): <class 'generator'>\n",
        "type(iter(gen_fib())): <class 'generator'>\n",
        "Are generators their own iterators? True\n",
        "f hasattr __iter__: True\n",
        "f hasattr __next__: True\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Under the hood, when Python sees `yield` inside of a function, it converts that function into a generator class using the logic inside of it. Calling `gen_fib` is very similar to what happens when you call `MyFibClass`, out pops an object. The actual implementation of generators is beyond the scope of this, however.\n",
      "\n",
      "##Actually using generators\n",
      "So, now we have this object, how can we get values out of it? The obvious answer is iteration! However, if you notice `gen_fib`'s while loop never exits, it's infinite. Attempting to consume the \"whole\" sequence will exhaust time (but honestly, it'll probably consume all your memory first, Fibonacci numbers get really big really quick). But just like with other iterators, `next` can be used to manually pull values of it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = gen_fib()\n",
      "print(next(f))\n",
      "print(next(f))\n",
      "print(next(f))\n",
      "print(next(f))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1\n",
        "1\n",
        "2\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, I mentioned that the flow control is actually more complicated than `list_fib`. Here's why and where the biggest difference between `yield` and `return` become known:\n",
      "\n",
      "* Assign the result of gen_fib() (a generator object) to f\n",
      "* Call next on f and print the value\n",
      "    * This runs the code down until the first yield statement which is:\n",
      "    * Assign 0 to a and 1 to b\n",
      "    * yield a (which is 0)\n",
      "* Call next on f and print the value\n",
      "    * yield b (which is 1)\n",
      "* Call next on f and print the value\n",
      "    * create a while loop on a true conditional\n",
      "    * yield a+b (1)\n",
      "* Call next on f and print the value\n",
      "    * assign b to a, assign a+b to b (this happens via tuple unpacking)\n",
      "    * while loop condition is still true\n",
      "    * yield a+b (2)\n",
      "\n",
      "If it's not obvious, a generator function is a function that \"pauses\" it's execution when it hit yield which also causes it spit out a value. Regular functions get one chance to run and return a value: they take some arguments, do something and then return a value. A generator takes some arguments, does something, yields a value and waits around to be called again. By not building a list that is potentially massive, generators can be incredibly memory efficient.\n",
      "\n",
      "This opens up a lot of possibilites:\n",
      "\n",
      "* Creating infinite sequences (perhaps the most mundane application, although incredibly handy)\n",
      "* Processing a large amount of data.\n",
      "* Creating a long sequence that you might not need all the values from (say I have a function that returns a list of twenty items but I only need the first ten)\n",
      "* Creating a long sequence where you don't need all the data at once (memory concerns, etc)\n",
      "* And others!\n",
      "\n",
      "And what's really cool, if you have a simple generator -- something like \"for each of these lines, yield one if it meets this simple requirement\" -- you can write a generator expression, here's a very contrived example."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nums = (num for num in range(1, 100) if not num%3)\n",
      "print(list(nums))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Gotchas\n",
      "The biggest most important gotcha is that generators are forgetful. What I mean by that, is when a generator hits `yield` it sends a value out. Unless the internal state that created value is met again, you can't get it back from the generator. Unlike `lists` and other types of iterables where you can iterate over the same object multiple times, generators are one time use. You can create multiple generator objects from the same function and iterate over each (and each will maintain their own state).\n",
      "\n",
      "As a consequence of this, searching a generator with `in` or by explicitly hitting `__contains__` will partially or wholly consume a generator. This is because `in` asks the generator, \"Hey, do you ever return this value?\" The generator gets to work yielding values out until one matches. All those values it outputs are gone. I suppose this could potentially be helpful in some situations, but I do want this caveat to be known.\n",
      "\n",
      "Another thing that will catch people off guard the first few times is that generators *don't* have a `__len__` property. Essentially, a generator has no idea how many values it will yield. It can't tell you that. Generators are also non-indexable for the same reason.\n",
      "\n",
      "##Delegating\n",
      "Up until now, these examples have been compatible between Python 2 and 3. However, in 3.3 a few changes were made to `yield` that took it from awesome to amazing. `yield` gained an optional keyword `from`. `yield from` delegates access from the current generator to one it's calling. The simplest way to understanding this is to know the next two code snippets output the same thing:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_chain_1(*iters):\n",
      "    '''This is actually the example code in the \n",
      "    itertools module for chain\n",
      "    '''\n",
      "    for it in iters:\n",
      "        for item in it:\n",
      "            yield item\n",
      "\n",
      "def my_chain_2(*iters):\n",
      "    '''This example completely removes a loop\n",
      "    '''\n",
      "    for it in iters:\n",
      "        yield from it\n",
      "\n",
      "a = range(2)\n",
      "b = range(5,7)\n",
      "\n",
      "print(list(my_chain_1(a,b)))\n",
      "print(list(my_chain_2(a,b)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 1, 5, 6]\n",
        "[0, 1, 5, 6]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The true power of `yield from` is that when you call `my_chain_2` you aren't simply being fed values from a inner generator. You are interacting directly with the inner generator. The impact of this is [profound](https://docs.python.org/3/library/asyncio.html). However, you don't need to construct an event loop to make use of this.\n",
      "\n",
      "##Real world use\n",
      "My canonical example is walking my `~/Music` directory and doing something with..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "find ~/Music -type f -name '*.mp3' | wc -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "18868\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...that number of files. To be honest, I'm not concerned about creating a list in memory of 19k file paths (typically a one time operation that I run every now and then). What I'm concerned with is *processing* 19k file paths in a timely fashion, let alone opening up the files, pulling information out of them and handling them. For the time being, I'm only going to operate on a very small subset of my library. I'm also going to show off how to build \"generator pipelines\" as Dave Beazley calls them.\n",
      "\n",
      "I do use a third party library here, `mutagenx` a Python3 implementation of `mutagen`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "from pprint import pprint\n",
      "\n",
      "from mutagenx import File\n",
      "\n",
      "valid_types=('m4a', 'flac', 'mp3', 'ogg', 'oga')\n",
      "\n",
      "def find(basedir, valid_types=valid_types):\n",
      "    '''Utilize os.walk to only select out the files we'd like to potentially\n",
      "    parse and yield them one at a time.'''\n",
      "    basedir = os.path.abspath(basedir)\n",
      "    for current, dirs, files in os.walk(basedir):\n",
      "        files = filter(lambda f: f.endswith(valid_types), sorted(files))\n",
      "        files = [os.path.join(current, f) for f in files]\n",
      "\n",
      "        if files:\n",
      "            yield from files\n",
      "\n",
      "def adaptor(track):\n",
      "    '''Take in a Mutagen track object and\n",
      "    parse it into a dictionary.\n",
      "    '''\n",
      "    return dict(\n",
      "        artist=track['artist'][0],\n",
      "        album=track['album'][0],\n",
      "        position=int(track['tracknumber'][0].split('/')[0]),\n",
      "        length=int(track.info.length),\n",
      "        location=track.filename,\n",
      "        name=track['title'][0],\n",
      "        )\n",
      "\n",
      "def process_directory(basedir, valid_types=valid_types):\n",
      "    '''Hook up find and adaptor into a pipeline'''\n",
      "    \n",
      "    files = find(basedir, valid_types)\n",
      "    tracks = (File(f, easy=True) for f in files)\n",
      "    yield from (adaptor(t) for t in tracks)\n",
      "\n",
      "tracks = process_directory('/home/justanr//Music/At the Drive-In/Relationship of Command')\n",
      "pprint(next(tracks))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'album': 'Relationship of Command',\n",
        " 'artist': 'At the Drive\u2010In',\n",
        " 'length': 177,\n",
        " 'location': '/home/justanr/Music/At the Drive-In/Relationship of Command/01 '\n",
        "             'Arcarsenal.mp3',\n",
        " 'name': 'Arcarsenal',\n",
        " 'position': 1}\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because of the nature of generators, only one item gets pulled down the line at a time. So, instead of processing the whole directory at once, we can process the directory one file at a time.\n",
      "\n",
      "yield and yield from also make processing trees easy as well. In the post on iteration, I showed a code example from the Python Cookbook that used a very complex iterator to maintain the state of iterating depth first over a tree. This is the same class built with generators:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Node:\n",
      "    def __init__(self, value):\n",
      "        self._value = value\n",
      "        self._children = []\n",
      "\n",
      "    def __repr__(self):\n",
      "        return 'Node({!r})'.format(self._value)\n",
      "\n",
      "    def add_child(self, node):\n",
      "        self._children.append(node)\n",
      "\n",
      "    def __iter__(self):\n",
      "        return iter(self._children)\n",
      "\n",
      "    def depth_first(self):\n",
      "        yield self\n",
      "        for c in self:\n",
      "            yield from c.depth_first()\n",
      "            \n",
      "root = Node(0)\n",
      "child1 = Node(1)\n",
      "child2 = Node(2)\n",
      "root.add_child(child1)\n",
      "root.add_child(child2)\n",
      "child1.add_child(Node(3))\n",
      "child1.add_child(Node(4))\n",
      "child2.add_child(Node(5))\n",
      "\n",
      "for ch in root.depth_first():\n",
      "    print(ch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Node(0)\n",
        "Node(1)\n",
        "Node(3)\n",
        "Node(4)\n",
        "Node(2)\n",
        "Node(5)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The entire `Node` class is 18 lines. The `DepthFirstIterator` alone is 30 lines. The logic is less complex.\n",
      "\n",
      "And of course, you can do bad things, too."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import chain\n",
      "\n",
      "class IterInt(int):\n",
      "    \n",
      "    def __iter__(self):\n",
      "        yield self\n",
      "\n",
      "def countdown(n):\n",
      "    n = IterInt(n)\n",
      "    if n < 0:\n",
      "        # wait... why are we returning here?\n",
      "        # I thought generators never returned!\n",
      "        return \"Countdown finished\"\n",
      "    else:\n",
      "        yield from chain(n, countdown(n-1))\n",
      "\n",
      "\n",
      "print(list(countdown(10)))\n",
      "try:\n",
      "    next(countdown(-1))\n",
      "except StopIteration as wut:\n",
      "    # no seriously...wut\n",
      "    print(wut)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
        "Countdown finished\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider it incentive for me to write more about generators.\n",
      "\n",
      "##Further Reading\n",
      "\n",
      "Generators are a really broad topic. For something that can be implemented for creating infinite sequences to being the backbone of event loops, there's quite a bit of ground to cover. There's a lot of really smart people out there writing things about them.\n",
      "\n",
      "* [David Bealey - Generator Tricks for Systems Programmers](http://www.dabeaz.com/generators-uk/)\n",
      "* [Jeff Knupp - Improve Your Python: 'yield' and Generators Explained](http://www.jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/)\n",
      "* [Simeon Visser - Python 3: Using \"yield from\" in Generators - Part 1](http://simeonvisser.com/posts/python-3-using-yield-from-in-generators-part-1.html) and...\n",
      "* [Simeon Visser - Python 3: Using \"yield from\" in Generators - Part 2](http://simeonvisser.com/posts/python-3-using-yield-from-in-generators-part-2.html)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}